{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e970f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.nn import functional as F\n",
    "from transformers import XLNetModel\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc03e5a",
   "metadata": {},
   "source": [
    "### NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995d6c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN, self).__init__()\n",
    "        self.xlnet = XLNetModel.from_pretrained('XLNet-path')\n",
    "        for param in self.xlnet.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.linear_1 = torch.nn.Linear(768,128)\n",
    "        self.linear_2 = torch.nn.Linear(20,128)\n",
    "        self.linear_3 = torch.nn.Linear(256,3)\n",
    "        self.dropout = torch.nn.Dropout(0.4)\n",
    "        self.act = torch.nn.Tanh()\n",
    "\n",
    "    def forward(self,x1,mask,x2):\n",
    "        encoder_out = self.xlnet(x1,attention_mask=mask)[0]\n",
    "        encoder_out,_ = torch.max(encoder_out,dim=1)\n",
    "        out_1 = self.linear_1(encoder_out)\n",
    "        out_1 = self.dropout(out_1)\n",
    "        \n",
    "        out_2 = self.linear_2(x2)\n",
    "        out_2 = self.dropout(out_2)\n",
    "        x = torch.concat([out_1,out_2],dim=1)\n",
    "        out = self.linear_3(x)\n",
    "        out = F.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cbaad4",
   "metadata": {},
   "source": [
    "### BiLSTM-CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a3f592",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM_CNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BiLSTM_CNN, self).__init__()\n",
    "        self.xlnet = XLNetModel.from_pretrained('XLNet-path')\n",
    "        for param in self.xlnet.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.bilstm = torch.nn.LSTM(\n",
    "            768,\n",
    "            128,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "            dropout=0.4,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        self.cnn = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(in_channels=20, out_channels=128, kernel_size=6,padding='same'),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.BatchNorm1d(128),\n",
    "            torch.nn.Conv1d(128,128,kernel_size=6,padding='same'),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "        self.dropout = torch.nn.Dropout(0.5)\n",
    "        self.linear_1 = torch.nn.Linear(256,128)\n",
    "        self.linear_2 = torch.nn.Linear(256,3)\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.act = torch.nn.Tanh()\n",
    "\n",
    "    def forward(self,x1,mask,x2):\n",
    "        encoder_out = self.xlnet(x1,attention_mask=mask)[0]\n",
    "        encoder_out,_ = torch.max(encoder_out,dim=1)\n",
    "        encoder_out = encoder_out.reshape(encoder_out.shape[0],1,-1)\n",
    "        out_1,_ = self.bilstm(encoder_out)\n",
    "        out_1 = self.dropout(out_1)\n",
    "        out_1 = out_1[:, -1, :]\n",
    "        out_1 = self.linear_1(out_1)\n",
    "        \n",
    "        x2 = x2.view(x2.shape[0],-1,1)\n",
    "        out_2 = self.cnn(x2)\n",
    "        out_2 = self.dropout(out_2)\n",
    "        out_2 = self.flatten(out_2)\n",
    "        x = torch.cat([out_1,out_2],dim=1)\n",
    "        out = self.linear_2(x)\n",
    "        out = F.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0197ae22",
   "metadata": {},
   "source": [
    "### DeleSmell model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26957cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU_Attention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GRU_Attention, self).__init__()\n",
    "        self.grus = nn.Sequential(\n",
    "            nn.GRU(input_size=768,hidden_size=128,num_layers=2,batch_first=True,dropout=0.5,bidirectional=True),\n",
    "        )\n",
    "        self.linear = nn.Linear(256,128)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.q = nn.Linear(256,256)\n",
    "        self.k = nn.Linear(256,256)\n",
    "        self.v = nn.Linear(256,256)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = x.view(x.shape[0],1,-1)\n",
    "        out,_ = self.grus(x)\n",
    "        out = self.dropout(out)\n",
    "        query = self.q(out)\n",
    "        key = self.k(out)\n",
    "        value = self.v(out)\n",
    "        attention = F.softmax(query @ key.transpose(1, 2) / math.sqrt(query.size(2)), dim=-1) @ value\n",
    "        out = self.flatten(attention)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(20,128,kernel_size=6,padding='same'),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self,inputs):\n",
    "        inputs = inputs.view(inputs.shape[0],-1,1)\n",
    "        out = self.conv(inputs)\n",
    "        out = self.dropout(out)\n",
    "        out = self.flatten(out)\n",
    "        return out\n",
    "\n",
    "class deleSmell(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(deleSmell, self).__init__()\n",
    "        self.xlnet = XLNetModel.from_pretrained('XLNet-path')\n",
    "        for param in self.xlnet.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.cnn = CNN()\n",
    "        self.gru_attention = GRU_Attention()\n",
    "        self.linear = nn.Linear(256,3)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self,x1,mask,x2):\n",
    "        encoder_out = self.xlnet(x1,attention_mask=mask)[0]\n",
    "        encoder_out,_ = torch.max(encoder_out,dim=1)\n",
    "        out_1 = self.gru_attention(encoder_out)\n",
    "        out_2 = self.cnn(x2)\n",
    "        x = torch.cat([out_1,out_2],dim=1)\n",
    "        out = self.linear(x)\n",
    "        out = F.sigmoid(out)\n",
    "        return out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
